# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oIZEOf8-heeqtlF3TNiTcAwO25UYfWd0

# Problem Statement
Your client is a large MNC and they have 9 broad verticals across the organisation. One of the problem your client is facing is around identifying the right people for promotion (only for manager position and below) and prepare them in time. Currently the process, they are following is:

They first identify a set of employees based on recommendations/ past performance

Selected employees go through the separate training and evaluation program for each vertical. These programs are based on the required skill of each vertical

At the end of the program, based on various factors such as training performance, KPI completion (only employees with KPIs completed greater than 60% are considered) etc., employee gets promotion

For above mentioned process, the final promotions are only announced after the evaluation and this leads to delay in transition to their new roles. Hence, company needs your help in identifying the eligible candidates at a particular checkpoint so that they can expedite the entire promotion cycle. ￼


They have provided multiple attributes around Employee's past and current performance along with demographics. Now, The task is to predict whether a potential promotee at checkpoint in the test set will be promoted or not after the evaluation process.
 

Dataset Description

Variable                  Definition
employee_id               Unique ID for employee
department                Department of employee
region                    Region of employment (unordered)
education                 Education Level
gender                    Gender of Employee
recruitment_channel       Channel of recruitment for employee
no_of_trainings           no of other trainings completed in previous year on
                          soft skills, technical skills etc.
age                       Age of Employee
previous_year_rating      Employee Rating for the previous year
length_of_service         Length of service in years
KPIs_met >80%             if Percent of KPIs(Key performance Indicators)
                          >80% then 1 else 0
awards_won?               if awards won during previous year then 1 else 0 avg_training_score        Average score in current training evaluations is_promoted(Target)       Recommended for promotion

 

Evaluation Metric

The evaluation metric for this competition is F1 Score.
 

Public and Private Split

Test data is further randomly divided into Public (40%) and Private (60%) data.

Your initial responses will be checked and scored on the Public data.

The final rankings would be based on your private score which will be published once the competition is over.

# Importing some necessory modules
Numpy- By numpy(Numerical Python) we can perform mathematical and logical operations on arrays.

Pandas- Pandas(Python Data Analysis Library) is used to analyze data and help us to manipulate data.

Matplotlib- Matplotlib is a plotting library for the Python programming language by this we can plot histogram,pieplot,linegraph etc.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""# Reading the csv file
For the comfortness i have uploaded the file in github and after that i use pd.read_csv(filepath) which return a Dataframe.
Let look how our dataset is. 
"""

data=pd.read_csv("https://raw.githubusercontent.com/RahulSinghPundir/Promotion-or-not/main/train_LZdllcl.csv")
data.head()

"""# Analysing dataset
First we note the size of our data that how large is our dataset. We found that we have 54808 rows and 14 columns.
Then we take an overview of our dataset that what type of features and label we have. 
"""

print("Shape: ",data.shape)
print(data.info())

"""# Balanced or Imbalanced
After observing our dataset we found that in the label there are 50140 which belonged to class 0 and only 4668 belonged to class 1. This can be clearly seen in the histogram graph.

So this means that our dataset is suffering from Imbalancing in which our data label has enough type of one class and less type of other class.
In this our model gets train with majority class and will give high accuracy for majority class but has low accuracy for miniority class.
"""

plt.hist(data.is_promoted)
plt.show()
data.is_promoted.value_counts()

"""# Cheacking for Null Values
There can be chance in the dataset we some null values. Null values are the missing values which should be handeled as it may lead to the overfitting problem. In our dataset we have 2409 values missing in education column and 4124 values missing in previous_year_rating.
"""

data.isnull().sum()

"""Feature extraction according to the Knowledge base:

employee_id- Obviosly employee id can be ignored because it can not provide any link towards promotion. 

department- Department sector is also unnecssory on which the promotion is not dependent.
Like that only we have many features(region, education, gender, recruitment_channel, no_of_trainings, age) which has no relation with the promotion.
"""

data=data[['previous_year_rating','length_of_service','KPIs_met >80%','awards_won?','avg_training_score','is_promoted']]

print("Previous Year Rating- \n",data.previous_year_rating.value_counts())

"""# Filling the Nan Values
We have some missing values in our dataset so we have two option we can left the whole row or we can fill it.
As we have few missing values so it is better to fill it with mean of that feature.
"""

df=data
df['previous_year_rating']=df['previous_year_rating'].fillna(df['previous_year_rating'].mean()).astype('int64')
df.isnull().sum()

"""# Co-relation
After selecting the features we are intrested in that how the features are affecting the label. -1 will indicate the feature is effecting in bad way 0 shows there is no relation between
"""

corrmat = df.corr() 
corrmat

"""# Heat Map
Heat mappinf technique is for visualising the numeric co relation the graph form.
"""

import seaborn as sns
f, ax = plt.subplots(figsize =(9, 8))
sns.heatmap(corrmat, ax = ax, cmap ="YlGnBu", linewidths = 0.1)

"""# Select the features and label column"""

X=df[['KPIs_met >80%','awards_won?','avg_training_score','previous_year_rating']]
Y=df.is_promoted

"""# Train Test Split
Now our dataset has two part in which first part will be used for training the model and the other part to find the accuracy.
"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size = 0.3, random_state = 0)
print(x_train.shape,y_test.shape)

y_train.value_counts()

"""We know that our data is imbalanced so we use synthetic minority oversampling technique to overcome from this situation."""

from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state = 2)
x_train, y_train = sm.fit_resample(x_train, y_train)
y_train.value_counts()

"""# GaussianNB
GaussianNB implements the Gaussian Naive Bayes algorithm for classification. The likelihood of the features is assumed to be Gaussian.
"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,accuracy_score,accuracy_score,f1_score
gnb = GaussianNB()
gnb.fit(x_train, y_train)
gnb_y_pred = gnb.predict(x_test)
print(confusion_matrix(y_test,gnb_y_pred,labels=[0,1]))
cm = confusion_matrix(y_test, gnb_y_pred, labels=gnb.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gnb.classes_)
disp.plot()
plt.show()
print('F1 is: ', f1_score(y_test,gnb_y_pred))
print("Accuracy Score:  ",accuracy_score(y_test,gnb_y_pred))

"""# Logistic regression
Logistic regression is basically a supervised classification algorithm. In a classification problem, the target variable(or output), y, can take only discrete values for a given set of features(or inputs), X. Contrary to popular belief, logistic regression IS a regression model.
"""

from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(x_train, y_train)
lr_y_pred = lr.predict(x_test)
cm = confusion_matrix(y_test, lr_y_pred, labels=lr.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr.classes_)
disp.plot()
plt.show()
print('F1 is: ', f1_score(y_test,lr_y_pred))
print("Accuracy Score:  ",accuracy_score(y_test,lr_y_pred))

"""# Reading the Testing Dataset"""

testdata=pd.read_csv("https://raw.githubusercontent.com/RahulSinghPundir/Promotion-or-not/main/test_2umaH9m.csv")
testdata.head()

"""# Extracting the features fronm testing dataset"""

X_test=testdata[['KPIs_met >80%','awards_won?','avg_training_score','previous_year_rating']]
X_test.head()

"""# Predicting the value for the test set """

X_test.previous_year_rating.fillna(X_test.previous_year_rating.mean(),inplace=True)
gnb_y_pred = gnb.predict(X_test)
gnb_y_pred

testdata.insert(13,"is_promoted",gnb_y_pred)

testdata.to_csv("predicted.csv")